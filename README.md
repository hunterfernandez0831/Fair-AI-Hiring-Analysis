# Fair-AI-Hiring-Analysis

## ğŸ“Œ Project Overview
This project explores whether AI resume screening tools introduce bias into the hiring process. Using a dataset of 1,000 anonymized applicants, fairness metrics like Demographic Parity and Disparate Impact were applied to identify potential issues and propose solutions.

## ğŸ“‚ Contents
- `presentation/`: Final presentation slides in PowerPoint format.
- `report/`: Written report detailing the business problem, dataset, methodology, and findings.
- `visuals/`: EDA charts and fairness metric visualizations (if applicable).

## âš™ï¸ Tools & Techniques
- Python (EDA, fairness metrics)
- Fairlearn or scikit-learn (for bias mitigation)
- Microsoft PowerPoint
- Word Processor (for documentation)

## ğŸ“Š Key Findings
- Traditional resume formatting can affect AI decisions.
- Salary expectations influenced outcomes.
- AI mirrored historical hiring patterns, penalizing non-traditional candidates.

## âœ… Recommendations
- Use fairness audits regularly.
- Maintain human oversight.
- Build diverse training data.

## ğŸ“£ Call to Action
Ensure AI supports ethical and equitable hiringâ€”don't let automation scale discrimination.
