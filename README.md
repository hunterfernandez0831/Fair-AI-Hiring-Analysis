# Fair-AI-Hiring-Analysis

## 📌 Project Overview
This project explores whether AI resume screening tools introduce bias into the hiring process. Using a dataset of 1,000 anonymized applicants, fairness metrics like Demographic Parity and Disparate Impact were applied to identify potential issues and propose solutions.

## 📂 Contents
- `presentation/`: Final presentation slides in PowerPoint format.
- `report/`: Written report detailing the business problem, dataset, methodology, and findings.
- `visuals/`: EDA charts and fairness metric visualizations (if applicable).

## ⚙️ Tools & Techniques
- Python (EDA, fairness metrics)
- Fairlearn or scikit-learn (for bias mitigation)
- Microsoft PowerPoint
- Word Processor (for documentation)

## 📊 Key Findings
- Traditional resume formatting can affect AI decisions.
- Salary expectations influenced outcomes.
- AI mirrored historical hiring patterns, penalizing non-traditional candidates.

## ✅ Recommendations
- Use fairness audits regularly.
- Maintain human oversight.
- Build diverse training data.

## 📣 Call to Action
Ensure AI supports ethical and equitable hiring—don't let automation scale discrimination.
